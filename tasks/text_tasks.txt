
1.1
	10, 12, 8, 3, 6, 19, #f, 4, 16, 6, 16

1.4
	Evaluate if-expr, a, b, apply if-expr.

1.5
	Applicative evaluation stucks on (p) evaluating recursion.
	Normal evaluation declines (p) evaluation in if-expression.

1.6
	In applicative-order interpreter all new-if parameters must be
	evaluated before new-if apply. So sqrt-iter stucks in recursion.

1.9
	1) => recursive (inc applied to + result)
	2) => iterative (simple call with new parameters)

1.10
	Math-only solution:
	Let's find A(m, n), m > 0, n > 0:
	1)	Suppose A(m, n) > 0

		1) A(0, 1) = 2
		2) A(1, n) = A(0, A(1, n - 1)) = 2 * A(1, n - 1)
			=> A(1, n) = 2 ^ n = hyper3(2, n)

	2)	Suppose A(m, n) = hyper[m+2](2, n)

		1) A(1, n) = 2 ^ n = hyper3(2, n)
			=> true
		2) A(m + 1, n) = A(m, A(m + 1, n - 1))
		=> hyper[m+3](2, n) = hyper[m+2](2, hyper[m+3](2, n - 1))
			=> if this is true then next is true

	=> A(m, n) = hyper[m+2](2, n)

	A(1, 10) = 2 ^ 10 = 1024
	A(2, 4)  = hyper4(2, 4) = 2 ^ 2 ^ 2 ^ 2 = 2 ^ 16 = 65536
	A(3, 3)  = hyper5(2, 3) = hyper4(2, hyper5(2, 2)) 		=
		 = hyper4(2, hyper4(2, hyper5(2, 1))) 			=
		 = hyper4(2, hyper4(2, hyper4(2, hyper4(2, 0))))	=
		 = hyper4(2, hyper4(2, hyper4(2, 1)))			=
			hyper4(2, n) = 2 ^ 2 ^ 2 ...
			hyper4(2, 1) = 2
			hyper4(2, 2) = 4
			hyper4(2, 4) = 2 ^ 16 = 65536

1.13
	1) Prove Fib(n) formula for n = 0, n = 1
	1) Prove that if Fib(n) formula is true for n, n + 1 then it's true
		for Fib(n + 2) = Fib(n + 1) + Fib(n)

	(sqrt(5) - 1) / 2 < 1/2 => Proved

1.14
	1 coin kind  => O(n)
	2 coin kinds => evaluations from 0 to n for O(n)   => O(n^2)
	3 coin kinds => evaluations from 0 to n for O(n^2) => O(n^3)
		and so on

	max tree depth:  O(n)   (memory)
	number of steps: O(n^m) (steps, m - number of coin kinds)

TODO:
1.15
1.20
1.25
1.26
1.34

2.15
	sigma(par1) ~ sR1 + sR2 + (sR1 * R1 + sR2 * R2) / (R1 + R2)
	sigma(par2) ~ (sR1 * R2 + sR2 * R1) / (R1 + R2)

	if R1 > 0, R2 > 0
	sigma(par1) > sigma(par2)

	That happens because of repetitions of R1 and R2 in par1 as
	different "measures".

	It is more correct here to estimate the error through
	partial derivatives d/dR1, d/dR2, so par2 is correct.

2.16
	Seems like it can be done by "naming" intervals and silently
	collecting them in one algebraic expression in data structure.
	Then we must find max(f(x1,x2,x3,...,xn)) on "interval"-
	closure in Rn. This is true rocket science.
